{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 1 : Filter the whole OpenFoodFacts database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "from typing import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFF_FILE = (\n",
    "    \"/home/mathieu/datasets/openfoodfacts/2024-07-19/en.openfoodfacts.org.products.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenFoodFacts website links to a file that [describes the data fields](https://static.openfoodfacts.org/data/data-fields.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first important information is that the OpenFoodFacts CSV file is encoded in UTF-8 and uses the TAB (`\\t`) character as delimiter.\n",
    "\n",
    "We will read the first 1,000 rows and see what data types are inferred by `read_csv`.\n",
    "\n",
    "Then we will assign explicit data types or convert values following a few guidelines :\n",
    "\n",
    "* Most of the columns in OpenFoodFacts contain nutritional values. Their name ends with `_100g` and their values are [decimal numerals](https://en.wikipedia.org/wiki/Decimal) ;\n",
    "* Columns ending with `_t` contain [Unix times](https://en.wikipedia.org/wiki/Unix_time) ;\n",
    "* Columns ending with `_datetime` contain date and time in [Coordinated Universal Time](https://en.wikipedia.org/wiki/Coordinated_Universal_Time) in the [ISO 8601 format](https://en.wikipedia.org/wiki/ISO_8601) ;\n",
    "* Columns ending with `_tags` are comma separated lists of (string) values.\n",
    "\n",
    "The `object` data type is the default data type in pandas, that is used whenever a column has non-numerical values.\n",
    "There is however a `string` data type that you can explicitly set for columns that contain textual values (strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set explicit data types for some columns\n",
    "OFF_DTYPES = {\n",
    "    \"code\": \"string\",  # barcode\n",
    "    \"url\": \"string\",  # URL on OFF\n",
    "    # metadata\n",
    "    # - OFF user names are \"category\"\n",
    "    # - Unix times and ISO 8601 datetimes are read as \"object\" to be cast explicitly later\n",
    "    \"creator\": \"category\",  # OFF user\n",
    "    \"created_t\": \"object\",  # post-processed\n",
    "    \"created_datetime\": \"object\",  # post-processed\n",
    "    \"last_modified_t\": \"object\",  # post-processed\n",
    "    \"last_modified_datetime\": \"object\",  # post-processed\n",
    "    \"last_modified_by\": \"category\",  # OFF user\n",
    "    \"last_updated_t\": \"object\",  # post-processed\n",
    "    \"last_updated_datetime\": \"object\",  # post-processed\n",
    "    #\n",
    "    \"product_name\": \"string\",\n",
    "    \"abbreviated_product_name\": \"string\",  # non-normalized, noisy ?\n",
    "    \"generic_name\": \"string\",\n",
    "    \"quantity\": \"string\",\n",
    "    # packaging has a taxonomy\n",
    "    \"packaging\": \"string\",  # list ; sep=','\n",
    "    \"packaging_tags\": \"string\",  # list ; sep=',' ; slightly normalized version of 'packaging'\n",
    "    \"packaging_en\": \"string\",  # list[str] ; sep=\",\" ; really a list of categories\n",
    "    \"packaging_text\": \"string\",  # plain text\n",
    "    # brands has no taxonomy\n",
    "    \"brands\": \"string\",  # list ; sep=\",\" (to normalize because \",  \" occurs)\n",
    "    \"brands_tags\": \"string\",  # list ; sep=',' ; slightly normalized version of 'brands'\n",
    "    # categories have a taxonomy and are (or should be) normalized\n",
    "    # => candidates for 'category', list of str, list of 'category' ?\n",
    "    # https://wiki.openfoodfacts.org/Data_fields#Categories\n",
    "    \"categories\": \"string\",  # list ; sep=\",\" (or \", \"? to normalize)\n",
    "    \"categories_tags\": \"string\",  # list ; sep=\",\" ; slightly normalized version of 'categories' ?\n",
    "    \"categories_en\": \"string\",  # list ; sep=\",\" ; plain text EN version of 'categories_tags' ?\n",
    "    # origins has no taxonomy\n",
    "    \"origins\": \"string\",  # list ; sep=',' ; not normalized\n",
    "    \"origins_tags\": \"string\",  # list ; sep=',' ; slightly normalized version of 'origins' but not enough\n",
    "    \"origins_en\": \"string\",  # list ; sep=',' ; plain text EN version of 'origins_tags' ? not enough\n",
    "    # manufacturing_places has no taxonomy\n",
    "    \"manufacturing_places\": \"string\",  # list ; sep=',' ; not normalized\n",
    "    \"manufacturing_places_tags\": \"string\",  # list ; sep=',' ; slightly normalized version of 'manufacturing_places'\n",
    "    # labels has a taxonomy\n",
    "    \"labels\": \"string\",  # list ; sep=',' (or ', '?); not normalized\n",
    "    \"labels_tags\": \"string\",  # list ; sep=',' (or ', '?); slightly normalized version of 'labels'\n",
    "    \"labels_en\": \"string\",  # list ; sep=',' ; plain text EN version of 'labels_tags'\n",
    "    #\n",
    "    \"emb_codes\": \"string\",  # list ; sep=',' (or ', '?); not normalized\n",
    "    \"emb_codes_tags\": \"string\",  # list ; sep=',' ; slightly normalized version of 'emb_codes'\n",
    "    # '(lat, lon)'\n",
    "    \"first_packaging_code_geo\": \"string\",  # FIXME\n",
    "    #\n",
    "    \"cities\": \"string\",  #  list[str] ; sep=',' ; currently empty\n",
    "    \"cities_tags\": \"string\",  # list[str] ; sep=',' ; slightly normalized\n",
    "    #\n",
    "    \"purchase_places\": \"string\",  # list ; sep=',' ; not normalized\n",
    "    \"stores\": \"string\",  # list ; sep=',' ; not normalized\n",
    "    #\n",
    "    \"countries\": \"string\",  # list ; sep=',' (or ', ' ?); not normalized\n",
    "    \"countries_tags\": \"string\",  # list ; sep=',' ; normalized version of 'countries'\n",
    "    \"countries_en\": \"string\",  # list ; sep=',' ; plain text EN version of 'countries_tags'\n",
    "    #\n",
    "    \"ingredients_text\": \"string\",\n",
    "    \"ingredients_tags\": \"string\",  # list ; sep=',' ; normalized version of 'ingredients'\n",
    "    \"ingredients_analysis_tags\": \"string\",  # list ; sep=',' ; normalized values eg. \"en:palm-oil-free,en:non-vegan\"\n",
    "    # ...\n",
    "    # TODO handle like states ? maybe use a cutoff to keep only the most frequent ones, and put the rest in a text column \"others\" ?\n",
    "    \"allergens\": \"string\",  # list[str] ; sep=',' (or ', ' ?); very noisy, so not currently a list of (normalized) categories\n",
    "    \"allergens_en\": \"string\",  # list[str] ; sep=',' (or ', ' ?); plain text EN version of 'allergens'  # currently empty\n",
    "    # TODO same (less urgent)\n",
    "    \"traces\": \"string\",  #  list ; sep=',' (or ', ' ?); normalized ?\n",
    "    \"traces_tags\": \"string\",  # list ; sep=',' (or ', ' ?); traces + automatic enrichment?\n",
    "    \"traces_en\": \"string\",  # list ; sep=',' (or ', ' ?); plain text EN version of 'traces_tags'\n",
    "    # https://wiki.openfoodfacts.org/Data_fields#Serving_size\n",
    "    \"serving_size\": \"string\",  # (2024-07-19: this is column number 50)\n",
    "    \"serving_quantity\": \"float\",  # computed from serving_size\n",
    "    # https://wiki.openfoodfacts.org/API_Fields\n",
    "    \"no_nutrition_data\": \"category\",  # former name: 'no_nutriments' ; values = \"on\", \"off\", \"true\", \"null\" ?\n",
    "    # additives\n",
    "    \"additives_n\": \"UInt8\",  # col 53\n",
    "    \"additives\": \"string\",  # list[str] ; sep=',' ; currently empty !?\n",
    "    \"additives_tags\": \"string\",  # list[str] ; sep=',' (or ', ' ?); normalized\n",
    "    \"additives_en\": \"string\",  # list[str] ; sep=',' (or ', ' ?); plain text EN version of 'additives_tags'\n",
    "    # palm: grouped and subsumed by new field \"ingredients_analysis_tags\"\n",
    "    # 'ingredients_from_palm_oil_n': 'UInt8',  # dropped\n",
    "    ## 'ingredients_from_palm_oil': 'string',  # list ; sep=',' ; currently empty !?\n",
    "    # 'ingredients_from_palm_oil_tags': 'string',  # list ; sep=',' (or ', ' ?); normalized\n",
    "    # 'ingredients_that_may_be_from_palm_oil_n': 'UInt8',\n",
    "    ## 'ingredients_that_may_be_from_palm_oil': 'string',  # list ; sep=',' ; currently empty !?\n",
    "    # 'ingredients_that_may_be_from_palm_oil_tags': 'string',  # list ; sep=',' (or ', ' ?); normalized\n",
    "    # synthetic scores, high-level information for customers\n",
    "    \"nutriscore_score\": \"Int8\",  # or Int64 ? ; col 57\n",
    "    \"nutriscore_grade\": CategoricalDtype(\n",
    "        categories=[\"a\", \"b\", \"c\", \"d\", \"e\"], ordered=True\n",
    "    ),  # \"unknown\" for missing values\n",
    "    \"nova_group\": CategoricalDtype(\n",
    "        categories=[\"1\", \"2\", \"3\", \"4\"], ordered=True\n",
    "    ),  # empty string for missing values\n",
    "    \"pnns_groups_1\": \"category\",  # there's an 'unknown' cat but also some NaN values !?\n",
    "    \"pnns_groups_2\": \"category\",  # id !?\n",
    "    \"food_groups\": \"category\",  # NEW : str ; either empty string or an atomic value like \"en:vegetables\"\n",
    "    \"food_groups_tags\": \"category\",  # NEW: list[str] ; sep=\",\" ; ex: \"en:fruits-and-vegetables,en:vegetables\"\n",
    "    \"food_groups_en\": \"category\",  # NEW: list[str] ; sep=\",\" ; ex: \"en:fruits-and-vegetables,en:vegetables\"\n",
    "    # states\n",
    "    \"states\": \"string\",  # post-processed ; list[str] ; sep=\", \"\n",
    "    \"states_tags\": \"string\",  # post-processed ;  list[str] ; sep=\",\"\n",
    "    \"states_en\": \"string\",  # post-processed ;  list[str] ; sep=\",\"\n",
    "    #\n",
    "    \"brand_owner\": \"string\",  # ?\n",
    "    # eco score\n",
    "    \"ecoscore_score\": \"float64\",  # should maybe be Int8 or Int64, but at least 1 float value stored as of 2024-07-19 ; renamed from \"ecoscore_score_fr\"  # col 69\n",
    "    \"ecoscore_grade\": CategoricalDtype(\n",
    "        categories=[\"a\", \"b\", \"c\", \"d\", \"e\"], ordered=True\n",
    "    ),  # renamed from \"ecoscore_grade_fr\"\n",
    "    # ?\n",
    "    \"nutrient_levels_tags\": \"string\",  # list[str] ; sep=\",\" ; really a list of categories\n",
    "    \"product_quantity\": \"float64\",  # new ; could be Int64 but many float values as of 2024-07\n",
    "    \"owner\": \"category\",  # new ; a few values with big arity, lots of values with small arity\n",
    "    \"data_quality_errors_tags\": \"string\",  # list[str] ; sep=\",\" ; really a list of categories\n",
    "    \"unique_scans_n\": \"Int64\",\n",
    "    \"popularity_tags\": \"string\",  # list[str] ; sep=\",\" ; really a list of categories\n",
    "    \"completeness\": \"float64\",  # in [0.0, 1.0] ; maximum 4 decimal digits\n",
    "    # metadata on images\n",
    "    \"last_image_t\": \"object\",  # post-processed\n",
    "    \"last_image_datetime\": \"object\",  # post-processed\n",
    "    # TODO categories are messy\n",
    "    \"main_category\": \"string\",\n",
    "    \"main_category_en\": \"string\",\n",
    "    # URLs\n",
    "    \"image_url\": \"string\",\n",
    "    \"image_small_url\": \"string\",\n",
    "    \"image_ingredients_url\": \"string\",\n",
    "    \"image_ingredients_small_url\": \"string\",\n",
    "    \"image_nutrition_url\": \"string\",\n",
    "    \"image_nutrition_small_url\": \"string\",\n",
    "    #\n",
    "    # 'nutrition-score-fr_100g': 'Int64',  # Int8 ?\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_COLS = {\n",
    "    # states and its variants\n",
    "    # 'states' cols have 42 unique values (as of 2021-08-16)\n",
    "    # we can have 41 at this stage, because we filtered entries with no\n",
    "    # 'image_small_url' (hence no 'image_url')\n",
    "    # which should amount to filtering out the tag 'Front-photo-not-selected'\n",
    "    \"states\": {\n",
    "        \"sep\": \",\",\n",
    "        \"alt_seps\": r\",\\s+\",\n",
    "        \"nb_uniq_vals\": (42, 41),\n",
    "    },\n",
    "    \"states_tags\": {\n",
    "        \"sep\": \",\",\n",
    "        \"alt_seps\": r\",\\s+\",\n",
    "        \"nb_uniq_vals\": (42, 41),\n",
    "    },\n",
    "    \"states_en\": {\n",
    "        \"sep\": \",\",\n",
    "        \"alt_seps\": r\",\\s+\",\n",
    "        \"nb_uniq_vals\": (42, 41),\n",
    "    },\n",
    "    # other columns\n",
    "    \"popularity_tags\": {\n",
    "        \"sep\": \",\",\n",
    "    },\n",
    "    \"nutrient_levels_tags\": {\n",
    "        \"sep\": \",\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_empty_columns(df, threshold=0.01, verbose=False):\n",
    "    \"\"\"Find empty or near-empty columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame\n",
    "    threshold : float\n",
    "        Proportion of values that must be non-null to consider a column non-empty.\n",
    "    verbose : boolean\n",
    "        If True, print the name and count of each empty column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    empty_cols : List[str]\n",
    "        Names of empty columns.\n",
    "    \"\"\"\n",
    "    empty_cols = []\n",
    "    nb_rows = df.shape[0]\n",
    "    if verbose:\n",
    "        print(\"nb_rows: \", nb_rows)\n",
    "    for col_name in df.columns:\n",
    "        if df[col_name].count() < threshold * nb_rows:\n",
    "            if verbose:\n",
    "                print(col_name, df[col_name].count())\n",
    "            empty_cols.append(col_name)\n",
    "    return empty_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_set_column(\n",
    "    df: pd.DataFrame,\n",
    "    col_name: str,\n",
    "    sep: str,\n",
    "    alt_seps: str | None = None,\n",
    "    nb_uniq_vals: Sequence[int] | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Replace a set-valued column with a set of boolean-valued columns.\n",
    "\n",
    "    A set column has values that are sets of categorical values (concretely in OFF:\n",
    "    lists of strings, whose linear order in a value is meaningless or can be recovered\n",
    "    from a taxonomy, and that are taken from a small inventory of possible values).\n",
    "    A set column can therefore be replaced with a semantically equivalent set of boolean\n",
    "    columns.\n",
    "    The process is somehow time-consuming and memory-intensive, but the resulting\n",
    "    DataFrame has a much smaller memory footprint, and is arguably easier to query.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df :\n",
    "        Original DataFrame\n",
    "    col_name :\n",
    "        Name of the set-valued column to replace.\n",
    "    sep :\n",
    "        Canonical separator between values.\n",
    "    alt_seps :\n",
    "        Pattern (regex) to capture non-canonical separators between values and replace\n",
    "        them with the canonical separator, as a preliminary canonicalization step.\n",
    "        This enables clean processing of non-canonical (legacy?) rows using eg. \", \"\n",
    "        instead of \",\".\n",
    "    nb_uniq_vals :\n",
    "        Expected numbers of unique values, for quality control.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    upd_df :\n",
    "        Updated DataFrame.\n",
    "    \"\"\"\n",
    "    # replace non-canonical separators with the canonical one, then split into atomic\n",
    "    # values\n",
    "    col_split = df[col_name].str.replace(alt_seps, sep).str.split(sep, expand=False)\n",
    "    # gather the set of unique atomic values, across all rows\n",
    "    uniq_vals = set(itertools.chain.from_iterable(col_split))\n",
    "    # control that the total number of unique values matches our expectation\n",
    "    # this is a quality check aimed at avoiding generating columns with non-canonical\n",
    "    # atomic values (ex: \" en:toto\") due to bad separators that escaped \"alt_seps\"\n",
    "    if nb_uniq_vals:\n",
    "        try:\n",
    "            assert len(uniq_vals) in nb_uniq_vals\n",
    "        except AssertionError:\n",
    "            print(len(uniq_vals))\n",
    "            # print(uniq_vals_dbg[col_name] - uniq_vals)\n",
    "            raise\n",
    "    # create a column for each atomic value in the set\n",
    "    new_cols = {\n",
    "        col_name + \"__\" + uniq_val: col_split.apply(lambda x: uniq_val in x)\n",
    "        for uniq_val in uniq_vals\n",
    "    }\n",
    "    upd_df = df.assign(**new_cols)\n",
    "    # drop the original column\n",
    "    upd_df.drop(columns=[col_name], inplace=True)\n",
    "    return upd_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_off_csv(\n",
    "    filepath_or_buffer,\n",
    "    dtype=None,\n",
    "    nrows: int | None = None,\n",
    "    threshold=0.01,\n",
    "    replace_set_columns=True,\n",
    "    split_geo=False,\n",
    "):\n",
    "    \"\"\"Load the OpenFoodFacts CSV file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath_or_buffer : str, path object or file-like object\n",
    "        Valid string path to the CSV file.\n",
    "    threshold : float\n",
    "        Threshold on the proportion of non-null values to consider a column non-empty.\n",
    "        0.01 means we keep all columns where at least 1% of the values are non-empty.\n",
    "    nrows : int, optional\n",
    "        Number of rows that should be read ; if None, read all.\n",
    "    replace_set_columns : boolean\n",
    "        If True, replace each set column (currently 'states', 'states_tags' and 'states_en' ;\n",
    "        'popularity_tags')\n",
    "        with a list of boolean columns. This requires to read a sample of the data first.\n",
    "    split_geo : boolean\n",
    "        If True, replace a geocode (string) column with two (float) columns for latitude and\n",
    "        longitude.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing the OpenFoodFacts tabular data.\n",
    "    \"\"\"\n",
    "    if (nrows is not None) and (not isinstance(nrows, int)):\n",
    "        # should not happen\n",
    "        print(f\"nrows is {nrows} but should be an int or None. Assumed None.\")\n",
    "        nrows = None\n",
    "\n",
    "    # 1. read a sample of the dataset, to get a sense of the columns: dtype, sparseness,\n",
    "    # number of unique values etc. and filter columns that will be of very little to no\n",
    "    # use\n",
    "    # by default, read the first 200_000 lines\n",
    "    df_sample = pd.read_csv(\n",
    "        filepath_or_buffer,\n",
    "        sep=\"\\t\",\n",
    "        dtype=dtype,\n",
    "        nrows=200_000,\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "        low_memory=False,\n",
    "    )\n",
    "\n",
    "    # 2. all columns were read from the header, and there are probably columns missing\n",
    "    # from the dtype specification (if any was given), especially among the \"_100g\" for\n",
    "    # nutritional values setup dtype\n",
    "    if dtype is None:\n",
    "        dtype = {}\n",
    "    else:\n",
    "        cols_sample_only = set(df_sample.columns.values) - set(dtype.keys())\n",
    "        try:\n",
    "            assert all(x.endswith(\"_100g\") for x in cols_sample_only)\n",
    "        except AssertionError:\n",
    "            print(\"Column names absent from dtype that do not end with '_100g':\")\n",
    "            for col_name in cols_sample_only:\n",
    "                if not col_name.endswith(\"_100g\"):\n",
    "                    uniq_vals = df_sample[col_name].unique()\n",
    "                    nuniq_vals = df_sample[col_name].nunique()\n",
    "                    nonnull_vals = df_sample[col_name].notnull().sum()\n",
    "                    print(\n",
    "                        f\"- {col_name}: \"\n",
    "                        + f\"{nonnull_vals} non-null values, \"\n",
    "                        + f\"{nuniq_vals} unique values\\n\"\n",
    "                        + f\"  {uniq_vals}\"\n",
    "                    )\n",
    "            print(\"All column names absent from dtype:\")\n",
    "            print(cols_sample_only)\n",
    "            print(\"Column names in dtype absent from the data sample:\")\n",
    "            print(set(dtype.keys()) - set(df_sample.columns.values))\n",
    "            raise\n",
    "    # explicitly set all (not yet defined) _100g to float\n",
    "    for col_name in df_sample.columns:\n",
    "        if col_name in dtype:\n",
    "            continue\n",
    "        if col_name.endswith(\"_100g\"):\n",
    "            dtype[col_name] = \"float\"\n",
    "\n",
    "    # filter rows :\n",
    "    # * product_name and brands\n",
    "    df_sample.drop(\n",
    "        df_sample[df_sample[\"product_name\"].isna() | df_sample[\"brands\"].isna()].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    # * entries that don't have an image for the (general aspect of the) product\n",
    "    df_sample.drop(df_sample[df_sample[\"image_small_url\"].isna()].index, inplace=True)\n",
    "    # * barcodes that are not of 8 or 13 characters long (EAN-8 or EAN-13)\n",
    "    df_sample.drop(\n",
    "        df_sample[\n",
    "            (df_sample[\"code\"].str.len() != 8) & (df_sample[\"code\"].str.len() != 13)\n",
    "        ].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    # * ambiguous barcodes, because they result in entries we cannot trust:\n",
    "    # incomplete, mixes of products...\n",
    "    #   - EAN8 : GS1-8 prefixes 000-099 and 200-299 \"Used to issue GS1 restricted circulation number within a company\"\n",
    "    #   (source: https://www.gs1.org/sites/default/files/docs/barcodes/WR15-006%20Updating%20Figures%20in%20General%20Specification_errataAnkurComment.pdf)\n",
    "    df_sample.drop(\n",
    "        df_sample[df_sample[\"code\"].str.fullmatch(r\"[02]\\d{7}\")].index, inplace=True\n",
    "    )\n",
    "    #   - EAN-13: GS1-13 prefix 00000 \"Reserved for GS1 Company Prefix equivalent of GS1-8 Prefix\"\n",
    "    df_sample.drop(\n",
    "        df_sample[df_sample[\"code\"].str.fullmatch(r\"00000[02]\\d{7}\")].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    #   - and just all those starting with 00000 because their URLs on the OFF website are all bad\n",
    "    df_sample.drop(\n",
    "        df_sample[df_sample[\"code\"].str.startswith(\"00000\")].index, inplace=True\n",
    "    )\n",
    "    # * entries that don't have complete categories\n",
    "    df_sample.drop(\n",
    "        df_sample[\n",
    "            df_sample[\"states_en\"].str.contains(\"Categories to be completed\")\n",
    "        ].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    # * entries that don't have complete nutritional values\n",
    "    df_sample.drop(\n",
    "        df_sample[\n",
    "            df_sample[\"states_en\"].str.contains(\"Nutrition facts to be completed\")\n",
    "        ].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # filter columns (to avoid loading) :\n",
    "    usecols = list(df_sample.columns)\n",
    "    # * URLs except 'url' and 'image_small_url'\n",
    "    extra_url_cols = [\n",
    "        x for x in df_sample.columns if x.endswith(\"_url\") and x != \"image_small_url\"\n",
    "    ]\n",
    "    df_sample.drop(columns=extra_url_cols, inplace=True)\n",
    "    usecols = [x for x in usecols if x not in extra_url_cols]\n",
    "    # TODO check they are effective duplicates\n",
    "    dup_cols = [\n",
    "        # \"_t\" are redundant with \"_datetime\"\n",
    "        \"created_t\",\n",
    "        \"last_modified_t\",\n",
    "        \"last_updated_t\",\n",
    "        \"last_image_t\",\n",
    "        # categories : we only keep the '_en' version of those\n",
    "        \"categories\",\n",
    "        \"categories_tags\",\n",
    "        \"main_category\",\n",
    "        \"origins\",\n",
    "        \"origins_tags\",\n",
    "        \"countries\",\n",
    "        \"countries_tags\",\n",
    "        \"brands_tags\",\n",
    "        \"labels\",\n",
    "        \"labels_tags\",\n",
    "        \"packaging_tags\",\n",
    "        \"states\",\n",
    "        \"states_tags\",\n",
    "        \"manufacturing_places_tags\",\n",
    "        \"traces\",\n",
    "        \"traces_tags\",\n",
    "    ]\n",
    "    df_sample.drop(columns=dup_cols, inplace=True)\n",
    "    usecols = [x for x in usecols if x not in dup_cols]\n",
    "    # * columns that are > 99% empty\n",
    "    empty_cols = find_empty_columns(df_sample, threshold=threshold, verbose=False)\n",
    "    df_sample.drop(columns=empty_cols, inplace=True)\n",
    "    usecols = [x for x in usecols if x not in empty_cols]\n",
    "\n",
    "    # read the requested amount of data\n",
    "    df = pd.read_csv(\n",
    "        filepath_or_buffer,\n",
    "        sep=\"\\t\",\n",
    "        usecols=usecols,\n",
    "        dtype=dtype,\n",
    "        nrows=nrows,\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "    )\n",
    "    # print(df.iloc[-1])  # DEBUG\n",
    "    # convert columns with unix timestamps and datetimes\n",
    "    for col_name in (\"created_t\", \"last_modified_t\", \"last_updated_t\", \"last_image_t\"):\n",
    "        if col_name not in usecols:\n",
    "            continue\n",
    "        # Unix timestamps\n",
    "        # NB : adding \".dt.tz_localize('UTC')\" results in the same value as in the _datetime field\n",
    "        df[col_name] = pd.to_datetime(df[col_name], unit=\"s\")\n",
    "    for col_name in (\n",
    "        \"created_datetime\",\n",
    "        \"last_modified_datetime\",\n",
    "        \"last_updated_datetime\",\n",
    "        \"last_image_datetime\",\n",
    "    ):\n",
    "        if col_name not in usecols:\n",
    "            continue\n",
    "        # ISO 8601 dates\n",
    "        df[col_name] = pd.to_datetime(df[col_name])\n",
    "\n",
    "    # filter rows :\n",
    "    # * entries with missing product_name or brands\n",
    "    df.drop(df[df[\"product_name\"].isna() | df[\"brands\"].isna()].index, inplace=True)\n",
    "    # * entries that don't have an image for the (general aspect of the) product\n",
    "    df.drop(df[df[\"image_small_url\"].isna()].index, inplace=True)\n",
    "    # (NB : .str methods in pandas are very slow, so it's way faster to apply them later)\n",
    "    # * barcodes that are not of 8 or 13 characters long (EAN-8 or EAN-13)\n",
    "    df.drop(\n",
    "        df[(df[\"code\"].str.len() != 8) & (df[\"code\"].str.len() != 13)].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    # * ambiguous barcodes, because they result in entries we cannot trust:\n",
    "    # incomplete, mixes of products...\n",
    "    #   - EAN-8: GS1-8 prefixes 000-099 and 200-299 \"Used to issue GS1 restricted circulation number within a company\"\n",
    "    #   (source: https://www.gs1.org/sites/default/files/docs/barcodes/WR15-006%20Updating%20Figures%20in%20General%20Specification_errataAnkurComment.pdf)\n",
    "    df.drop(df[df[\"code\"].str.fullmatch(r\"[02]\\d{7}\")].index, inplace=True)\n",
    "    #   - EAN-13: GS1-13 prefix 00000 \"Reserved for GS1 Company Prefix equivalent of GS1-8 Prefix\"\n",
    "    df.drop(df[df[\"code\"].str.fullmatch(r\"00000[02]\\d{7}\")].index, inplace=True)\n",
    "    #   - and just all those starting with 00000 because their URLs on the OFF website are all bad\n",
    "    df.drop(df[df[\"code\"].str.startswith(\"00000\")].index, inplace=True)\n",
    "    # * entries that don't have categories\n",
    "    df.drop(\n",
    "        df[df[\"states_en\"].str.contains(\"Categories to be completed\")].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    # * entries that don't have complete nutritional values\n",
    "    df.drop(\n",
    "        df[df[\"states_en\"].str.contains(\"Nutrition facts to be completed\")].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    # remove unused categories for 'creator' and 'last_modified_by'\n",
    "    # df['creator'].cat.remove_unused_categories()\n",
    "    # df['last_modified_by'].cat.remove_unused_categories()\n",
    "    # I'm not entirely sure how to use this and the user guide might not be up-to-date here\n",
    "    # https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.remove_unused_categories.html\n",
    "\n",
    "    # filter columns (again, because we read the full dataset (and not the first 200k lines\n",
    "    # and we dropped entries):\n",
    "    # * columns that are > 99% empty\n",
    "    empty_cols = find_empty_columns(df, threshold=threshold, verbose=False)\n",
    "    df.drop(columns=empty_cols, inplace=True)\n",
    "    usecols = [x for x in usecols if x not in empty_cols]\n",
    "\n",
    "    if replace_set_columns:\n",
    "        # replace each set column with a set of boolean columns ;\n",
    "        # 'states' columns have 42 atomic values, much lower than the 5903 distinct occurring\n",
    "        # combinations (as of 2021-08-16)\n",
    "        for col_name, col_specs in SET_COLS.items():\n",
    "            if col_name not in usecols:\n",
    "                continue\n",
    "            df = replace_set_column(df=df, col_name=col_name, **col_specs)\n",
    "\n",
    "    if split_geo:\n",
    "        # first_packaging_code_geo: split latitude and longitude, cast as floats\n",
    "        col_name = \"first_packaging_code_geo\"\n",
    "        df_col = df[col_name].str.split(\",\", expand=True)\n",
    "        df_col[0] = pd.to_numeric(df_col[0], errors=\"coerce\")\n",
    "        df_col[1] = pd.to_numeric(df_col[1], errors=\"coerce\")\n",
    "        df_col.rename(\n",
    "            columns={0: col_name + \"__\" + \"lat\", 1: col_name + \"__\" + \"lon\"},\n",
    "            inplace=True,\n",
    "        )\n",
    "        df = df.join(df_col)\n",
    "        df.drop(columns=[\"first_packaging_code_geo\"], inplace=True)\n",
    "    #\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 778725 entries, 1074 to 3333499\n",
      "Data columns (total 81 columns):\n",
      " #   Column                                                 Non-Null Count   Dtype              \n",
      "---  ------                                                 --------------   -----              \n",
      " 0   code                                                   778725 non-null  string             \n",
      " 1   url                                                    778725 non-null  string             \n",
      " 2   creator                                                778724 non-null  category           \n",
      " 3   created_datetime                                       778725 non-null  datetime64[ns, UTC]\n",
      " 4   last_modified_datetime                                 778725 non-null  datetime64[ns, UTC]\n",
      " 5   last_modified_by                                       772572 non-null  category           \n",
      " 6   last_updated_datetime                                  766338 non-null  datetime64[ns, UTC]\n",
      " 7   product_name                                           778725 non-null  string             \n",
      " 8   generic_name                                           133394 non-null  string             \n",
      " 9   quantity                                               514927 non-null  string             \n",
      " 10  packaging                                              286780 non-null  string             \n",
      " 11  packaging_en                                           286776 non-null  string             \n",
      " 12  packaging_text                                         22995 non-null   string             \n",
      " 13  brands                                                 778725 non-null  string             \n",
      " 14  categories_en                                          778718 non-null  string             \n",
      " 15  origins_en                                             108132 non-null  string             \n",
      " 16  manufacturing_places                                   158754 non-null  string             \n",
      " 17  labels_en                                              411490 non-null  string             \n",
      " 18  emb_codes                                              118839 non-null  string             \n",
      " 19  emb_codes_tags                                         118817 non-null  string             \n",
      " 20  purchase_places                                        168929 non-null  string             \n",
      " 21  stores                                                 283919 non-null  string             \n",
      " 22  countries_en                                           775353 non-null  string             \n",
      " 23  ingredients_text                                       486644 non-null  string             \n",
      " 24  ingredients_tags                                       485365 non-null  string             \n",
      " 25  ingredients_analysis_tags                              497319 non-null  string             \n",
      " 26  allergens                                              184775 non-null  string             \n",
      " 27  traces_en                                              138732 non-null  string             \n",
      " 28  serving_size                                           233972 non-null  string             \n",
      " 29  serving_quantity                                       228111 non-null  float64            \n",
      " 30  no_nutrition_data                                      30882 non-null   category           \n",
      " 31  additives_n                                            486647 non-null  UInt8              \n",
      " 32  additives_tags                                         258433 non-null  string             \n",
      " 33  additives_en                                           258433 non-null  string             \n",
      " 34  nutriscore_score                                       652630 non-null  Int8               \n",
      " 35  nutriscore_grade                                       652630 non-null  category           \n",
      " 36  nova_group                                             461602 non-null  category           \n",
      " 37  pnns_groups_1                                          778723 non-null  category           \n",
      " 38  pnns_groups_2                                          778725 non-null  category           \n",
      " 39  food_groups                                            659942 non-null  category           \n",
      " 40  food_groups_tags                                       659942 non-null  category           \n",
      " 41  food_groups_en                                         659942 non-null  category           \n",
      " 42  states_en                                              778725 non-null  string             \n",
      " 43  brand_owner                                            38646 non-null   string             \n",
      " 44  ecoscore_score                                         499542 non-null  float64            \n",
      " 45  ecoscore_grade                                         499542 non-null  category           \n",
      " 46  nutrient_levels_tags                                   708860 non-null  string             \n",
      " 47  product_quantity                                       501910 non-null  float64            \n",
      " 48  data_quality_errors_tags                               28242 non-null   string             \n",
      " 49  unique_scans_n                                         515398 non-null  Int64              \n",
      " 50  popularity_tags                                        510976 non-null  string             \n",
      " 51  completeness                                           778725 non-null  float64            \n",
      " 52  last_image_datetime                                    778724 non-null  datetime64[ns, UTC]\n",
      " 53  main_category_en                                       778718 non-null  string             \n",
      " 54  image_small_url                                        778725 non-null  string             \n",
      " 55  energy-kj_100g                                         233932 non-null  float64            \n",
      " 56  energy-kcal_100g                                       688304 non-null  float64            \n",
      " 57  energy_100g                                            724951 non-null  float64            \n",
      " 58  fat_100g                                               722357 non-null  float64            \n",
      " 59  saturated-fat_100g                                     710026 non-null  float64            \n",
      " 60  monounsaturated-fat_100g                               15327 non-null   float64            \n",
      " 61  polyunsaturated-fat_100g                               15345 non-null   float64            \n",
      " 62  trans-fat_100g                                         41861 non-null   float64            \n",
      " 63  cholesterol_100g                                       42341 non-null   float64            \n",
      " 64  carbohydrates_100g                                     722492 non-null  float64            \n",
      " 65  sugars_100g                                            713746 non-null  float64            \n",
      " 66  fiber_100g                                             357598 non-null  float64            \n",
      " 67  proteins_100g                                          722272 non-null  float64            \n",
      " 68  salt_100g                                              685614 non-null  float64            \n",
      " 69  sodium_100g                                            685613 non-null  float64            \n",
      " 70  alcohol_100g                                           23116 non-null   float64            \n",
      " 71  vitamin-a_100g                                         27497 non-null   float64            \n",
      " 72  vitamin-d_100g                                         11431 non-null   float64            \n",
      " 73  vitamin-c_100g                                         29166 non-null   float64            \n",
      " 74  vitamin-b1_100g                                        8831 non-null    float64            \n",
      " 75  vitamin-b2_100g                                        8718 non-null    float64            \n",
      " 76  potassium_100g                                         26339 non-null   float64            \n",
      " 77  calcium_100g                                           53406 non-null   float64            \n",
      " 78  iron_100g                                              43830 non-null   float64            \n",
      " 79  fruits-vegetables-nuts-estimate-from-ingredients_100g  485376 non-null  float64            \n",
      " 80  nutrition-score-fr_100g                                652630 non-null  float64            \n",
      "dtypes: Int64(1), Int8(1), UInt8(1), category(11), datetime64[ns, UTC](4), float64(30), string(33)\n",
      "memory usage: 2.8 GB\n"
     ]
    }
   ],
   "source": [
    "df = load_off_csv(\n",
    "    OFF_FILE, dtype=OFF_DTYPES, nrows=None, replace_set_columns=False\n",
    ")  # 1_546_028 ok, 1_546_029 not ok\n",
    "# old: 416_552 rows, 66 columns, 1.0 GB (76 s)\n",
    "# 2024:\n",
    "# - nrows=2_000_000: 411940 rows, 85 columns, 1.5 GB (148 s)\n",
    "# - nrows=3_333_516: 778725 rows, 81 columns, 2.8 GB (248 to 298 s)\n",
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ingredients_analysis_tags</th>\n",
       "      <td>67191862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_name</th>\n",
       "      <td>67330594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_small_url</th>\n",
       "      <td>109971672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>114245846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nutrient_levels_tags</th>\n",
       "      <td>119973664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories_en</th>\n",
       "      <td>120609884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ingredients_text</th>\n",
       "      <td>184003965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ingredients_tags</th>\n",
       "      <td>209272621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity_tags</th>\n",
       "      <td>363863154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>states_en</th>\n",
       "      <td>380210073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0\n",
       "ingredients_analysis_tags   67191862\n",
       "product_name                67330594\n",
       "image_small_url            109971672\n",
       "url                        114245846\n",
       "nutrient_levels_tags       119973664\n",
       "categories_en              120609884\n",
       "ingredients_text           184003965\n",
       "ingredients_tags           209272621\n",
       "popularity_tags            363863154\n",
       "states_en                  380210073"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.memory_usage(deep=True).sort_values()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                                                                              <NA>,\n",
       "                                          'en:palm-oil-free,en:vegan,en:vegetarian',\n",
       " 'en:palm-oil-content-unknown,en:vegan-status-unknown,en:vegetarian-status-unknown',\n",
       "                               'en:may-contain-palm-oil,en:non-vegan,en:vegetarian',\n",
       " 'en:palm-oil-content-unknown,en:vegan-status-unknown,en:vegetarian-status-unknown']\n",
       "Length: 5, dtype: string"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new set columns: \"popularity_tags\", \"ingredients_tags\" (?)\n",
    "df[\"ingredients_analysis_tags\"].iloc[:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                                                                                                                                                                                                                                                                                                        <NA>,\n",
       "                                                                        'Water, Lime Juice from Concentrate (30%), Acid: Citric Acid; Preservatives: Potassium Sorbate, Sodium Metabisulphite (Sulphites); Flavourings, Antioxidant: Ascorbic Acid; Acidity Regulator: Sodium Citrate; Sweetener: Sucralose.',\n",
       "                                                                                                                                'pâte 66.7%. farine de BLE  beurre (lait) 18,6%. eau sel levure désactivée.  Garniture compote de pommes 30,5%: purée de pommes concentrée, sirop de glucose fructose (BLE).',\n",
       "                                                                                                                                                     'Sugar, cocoa butter, skimmed milk powder, cocoa mass, whey powder (from milk), lactose, milk fat, emulsifier (soya lecithin), natural vanilla extract.',\n",
       " 'Hafervollkornflocken, Rohrzucker, extrudiertes Getreideerzeugnis (Reismehl, Weizenmehl, Rohrzucker, Gerstenmalzmehl Meersalz), Rapsöl&quot;, Reissirup&quot;, gefriergetrocknete Mangostücke&quot; (2,5 %), Maracuja - fruchtsaftpulver&quot;) (Maracujasaftkonzentrat&quot;, Maisstärke&quot;), Meersalz.']\n",
       "Length: 5, dtype: string"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"ingredients_tags\" is a list of categorical values: each ingredient generates 1-n language-prefixed tags\n",
    "# ex:\n",
    "# * ingredients_text = \"Hafervollkornflocken, Rohrzucker\"\n",
    "# * ingredients_tags = \"en:whole-grain-oat-flakes,en:cereal,en:oat,en:oat-flakes,en:cane-sugar,en:added-sugar,en:disaccharide,en:sugar\"\n",
    "df[\"ingredients_text\"].iloc[:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652630"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"nutriscore_score\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vitamin-b2_100g              8718\n",
       "vitamin-b1_100g              8831\n",
       "vitamin-d_100g              11431\n",
       "monounsaturated-fat_100g    15327\n",
       "polyunsaturated-fat_100g    15345\n",
       "packaging_text              22995\n",
       "alcohol_100g                23116\n",
       "potassium_100g              26339\n",
       "vitamin-a_100g              27497\n",
       "data_quality_errors_tags    28242\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of non-null values of the 10 sparsest columns\n",
    "df.count().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0000131327786',\n",
       "        'http://world-en.openfoodfacts.org/product/0000131327786/lime-cordial-sainsbury-s',\n",
       "        'blakejones99', Timestamp('2024-06-01 20:48:44+0000', tz='UTC'),\n",
       "        Timestamp('2024-06-01 22:13:50+0000', tz='UTC'), 'roboto-app',\n",
       "        Timestamp('2024-06-01 22:13:50+0000', tz='UTC'), 'Lime Cordial',\n",
       "        <NA>, '1l', <NA>, <NA>, <NA>, \"Sainsbury's\", 'Lime-cordial',\n",
       "        <NA>, <NA>, 'Vegetarian,Vegan,No added sugar', <NA>, <NA>, <NA>,\n",
       "        \"Sainsbury's\", 'United Kingdom',\n",
       "        'Water, Lime Juice from Concentrate (30%), Acid: Citric Acid; Preservatives: Potassium Sorbate, Sodium Metabisulphite (Sulphites); Flavourings, Antioxidant: Ascorbic Acid; Acidity Regulator: Sodium Citrate; Sweetener: Sucralose.',\n",
       "        'en:water,en:lime-juice-concentrate,en:fruit,en:citrus-fruit,en:juice,en:fruit-juice,en:lime,en:lime-juice,en:acid,en:preservative,en:e223,en:flavouring,en:antioxidant,en:acidity-regulator,en:sweetener,en:e330,en:e202,en:e300,en:sodium-citrate,en:minerals,en:sodium,en:e955',\n",
       "        'en:palm-oil-free,en:vegan,en:vegetarian',\n",
       "        'en:sulphur-dioxide-and-sulphites', <NA>, <NA>, nan, nan, 6,\n",
       "        'en:e202,en:e223,en:e300,en:e330,en:e331,en:e955',\n",
       "        'E202 - Potassium sorbate,E223 - Sodium metabisulphite,E300 - Ascorbic acid,E330 - Citric acid,E331 - Sodium citrates,E955 - Sucralose',\n",
       "        <NA>, nan, '4', 'unknown', 'unknown', nan, nan, nan,\n",
       "        'To be completed,Nutrition facts completed,Ingredients completed,Expiration date to be completed,Packaging code to be completed,Characteristics to be completed,Origins to be completed,Categories completed,Brands completed,Packaging to be completed,Quantity completed,Product name completed,Photos validated,Packaging photo selected,Nutrition photo selected,Ingredients photo selected,Front photo selected,Photos uploaded',\n",
       "        <NA>, nan, nan, <NA>, 1000.0, <NA>, <NA>, <NA>, 0.7,\n",
       "        Timestamp('2024-06-01 20:49:51+0000', tz='UTC'), 'Lime-cordial',\n",
       "        'https://images.openfoodfacts.org/images/products/000/013/132/7786/front_en.3.200.jpg',\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 30.0, nan]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first entry\n",
    "df.head(2).tail(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': string[python],\n",
       " 'url': string[python],\n",
       " 'creator': CategoricalDtype(categories=['a-avilaaa', 'abdoubasbas', 'acistopogm', 'agamitsudo',\n",
       "                   'alaetien', 'alban14121999', 'allergies-app-chakib',\n",
       "                   'allfitnessfactory-de', 'aly22', 'andre',\n",
       "                   ...\n",
       "                   'lion76', 'lookatchu', 'malard', 'mordragt', 'purplesam',\n",
       "                   'randy1156', 'serayet', 'town1997', 'deeulyana', 'jrg2024'],\n",
       " , ordered=False),\n",
       " 'created_datetime': datetime64[ns, UTC],\n",
       " 'last_modified_datetime': datetime64[ns, UTC],\n",
       " 'last_modified_by': CategoricalDtype(categories=['5m4u9', 'acistopogm', 'agamitsudo', 'akaandrew', 'aleene',\n",
       "                   'alexfauquette', 'alexouille', 'alibunt',\n",
       "                   'allergies-app-chakib', 'angharadpike',\n",
       "                   ...\n",
       "                   'philanne', 'themindasrimal', 'xhxhd', 'yamum', 'zangele',\n",
       "                   'afracnicus', 'backpedal', 'fitster', 'soefo', 'yanisro'],\n",
       " , ordered=False),\n",
       " 'last_updated_datetime': datetime64[ns, UTC],\n",
       " 'product_name': string[python],\n",
       " 'generic_name': string[python],\n",
       " 'quantity': string[python],\n",
       " 'packaging': string[python],\n",
       " 'packaging_en': string[python],\n",
       " 'packaging_text': string[python],\n",
       " 'brands': string[python],\n",
       " 'categories_en': string[python],\n",
       " 'origins_en': string[python],\n",
       " 'manufacturing_places': string[python],\n",
       " 'labels_en': string[python],\n",
       " 'emb_codes': string[python],\n",
       " 'emb_codes_tags': string[python],\n",
       " 'purchase_places': string[python],\n",
       " 'stores': string[python],\n",
       " 'countries_en': string[python],\n",
       " 'ingredients_text': string[python],\n",
       " 'ingredients_tags': string[python],\n",
       " 'ingredients_analysis_tags': string[python],\n",
       " 'allergens': string[python],\n",
       " 'traces_en': string[python],\n",
       " 'serving_size': string[python],\n",
       " 'serving_quantity': dtype('float64'),\n",
       " 'no_nutrition_data': CategoricalDtype(categories=['off', 'on', 'true', 'false'], ordered=False),\n",
       " 'additives_n': UInt8Dtype(),\n",
       " 'additives_tags': string[python],\n",
       " 'additives_en': string[python],\n",
       " 'nutriscore_score': Int8Dtype(),\n",
       " 'nutriscore_grade': CategoricalDtype(categories=['a', 'b', 'c', 'd', 'e'], ordered=True),\n",
       " 'nova_group': CategoricalDtype(categories=['1', '2', '3', '4'], ordered=True),\n",
       " 'pnns_groups_1': CategoricalDtype(categories=['Alcoholic beverages', 'Beverages', 'Cereals and potatoes',\n",
       "                   'Composite foods', 'Fat and sauces', 'Fish Meat Eggs',\n",
       "                   'Fruits and vegetables', 'Milk and dairy products',\n",
       "                   'Salty snacks', 'Sugary snacks', 'unknown', 'sugary-snacks'],\n",
       " , ordered=False),\n",
       " 'pnns_groups_2': CategoricalDtype(categories=['Alcoholic beverages', 'Appetizers', 'Biscuits and cakes',\n",
       "                   'Bread', 'Breakfast cereals', 'Cereals', 'Cheese',\n",
       "                   'Chocolate products', 'Dairy desserts',\n",
       "                   'Dressings and sauces', 'Dried fruits', 'Eggs', 'Fats',\n",
       "                   'Fish and seafood', 'Fruit juices', 'Fruits', 'Ice cream',\n",
       "                   'Legumes', 'Meat', 'Milk and yogurt', 'Nuts',\n",
       "                   'One-dish meals', 'Pastries', 'Pizza pies and quiches',\n",
       "                   'Plant-based milk substitutes', 'Processed meat',\n",
       "                   'Salty and fatty products', 'Sandwiches', 'Soups',\n",
       "                   'Sweetened beverages', 'Sweets',\n",
       "                   'Teas and herbal teas and coffees', 'Unsweetened beverages',\n",
       "                   'Vegetables', 'unknown', 'Artificially sweetened beverages',\n",
       "                   'Offals', 'Potatoes', 'Waters and flavored waters',\n",
       "                   'Fruit nectars', 'pastries', 'Pizza pies and quiche'],\n",
       " , ordered=False),\n",
       " 'food_groups': CategoricalDtype(categories=['en:alcoholic-beverages', 'en:appetizers',\n",
       "                   'en:biscuits-and-cakes', 'en:bread', 'en:breakfast-cereals',\n",
       "                   'en:cereals', 'en:cereals-and-potatoes', 'en:cheese',\n",
       "                   'en:chocolate-products', 'en:dairy-desserts',\n",
       "                   'en:dressings-and-sauces', 'en:dried-fruits', 'en:eggs',\n",
       "                   'en:fats', 'en:fatty-fish', 'en:fish-and-seafood',\n",
       "                   'en:fruit-juices', 'en:fruits', 'en:fruits-and-vegetables',\n",
       "                   'en:ice-cream', 'en:lean-fish', 'en:legumes',\n",
       "                   'en:meat-other-than-poultry', 'en:milk-and-yogurt',\n",
       "                   'en:nuts', 'en:one-dish-meals', 'en:pastries',\n",
       "                   'en:pizza-pies-and-quiches',\n",
       "                   'en:plant-based-milk-substitutes', 'en:poultry',\n",
       "                   'en:processed-meat', 'en:salty-and-fatty-products',\n",
       "                   'en:sandwiches', 'en:soups', 'en:sweetened-beverages',\n",
       "                   'en:sweets', 'en:teas-and-herbal-teas-and-coffees',\n",
       "                   'en:unknown', 'en:unsweetened-beverages', 'en:vegetables',\n",
       "                   'en:artificially-sweetened-beverages', 'en:offals',\n",
       "                   'en:potatoes', 'en:waters-and-flavored-waters',\n",
       "                   'en:fruit-nectars', 'en:fish-meat-eggs'],\n",
       " , ordered=False),\n",
       " 'food_groups_tags': CategoricalDtype(categories=['en:alcoholic-beverages', 'en:beverages,en:fruit-juices',\n",
       "                   'en:beverages,en:plant-based-milk-substitutes',\n",
       "                   'en:beverages,en:sweetened-beverages',\n",
       "                   'en:beverages,en:teas-and-herbal-teas-and-coffees',\n",
       "                   'en:beverages,en:unsweetened-beverages',\n",
       "                   'en:cereals-and-potatoes',\n",
       "                   'en:cereals-and-potatoes,en:bread',\n",
       "                   'en:cereals-and-potatoes,en:breakfast-cereals',\n",
       "                   'en:cereals-and-potatoes,en:cereals',\n",
       "                   'en:cereals-and-potatoes,en:legumes',\n",
       "                   'en:composite-foods,en:one-dish-meals',\n",
       "                   'en:composite-foods,en:pizza-pies-and-quiches',\n",
       "                   'en:composite-foods,en:sandwiches',\n",
       "                   'en:fats-and-sauces,en:dressings-and-sauces',\n",
       "                   'en:fats-and-sauces,en:fats', 'en:fish-meat-eggs,en:eggs',\n",
       "                   'en:fish-meat-eggs,en:fish-and-seafood',\n",
       "                   'en:fish-meat-eggs,en:fish-and-seafood,en:fatty-fish',\n",
       "                   'en:fish-meat-eggs,en:fish-and-seafood,en:lean-fish',\n",
       "                   'en:fish-meat-eggs,en:meat,en:meat-other-than-poultry',\n",
       "                   'en:fish-meat-eggs,en:meat,en:poultry',\n",
       "                   'en:fish-meat-eggs,en:processed-meat',\n",
       "                   'en:fruits-and-vegetables',\n",
       "                   'en:fruits-and-vegetables,en:dried-fruits',\n",
       "                   'en:fruits-and-vegetables,en:fruits',\n",
       "                   'en:fruits-and-vegetables,en:soups',\n",
       "                   'en:fruits-and-vegetables,en:vegetables',\n",
       "                   'en:milk-and-dairy-products,en:cheese',\n",
       "                   'en:milk-and-dairy-products,en:dairy-desserts',\n",
       "                   'en:milk-and-dairy-products,en:ice-cream',\n",
       "                   'en:milk-and-dairy-products,en:milk-and-yogurt',\n",
       "                   'en:salty-snacks,en:appetizers', 'en:salty-snacks,en:nuts',\n",
       "                   'en:salty-snacks,en:salty-and-fatty-products',\n",
       "                   'en:sugary-snacks,en:biscuits-and-cakes',\n",
       "                   'en:sugary-snacks,en:chocolate-products',\n",
       "                   'en:sugary-snacks,en:pastries', 'en:sugary-snacks,en:sweets',\n",
       "                   'en:unknown',\n",
       "                   'en:beverages,en:artificially-sweetened-beverages',\n",
       "                   'en:beverages,en:waters-and-flavored-waters',\n",
       "                   'en:cereals-and-potatoes,en:potatoes',\n",
       "                   'en:fish-meat-eggs,en:offals',\n",
       "                   'en:beverages,en:fruit-nectars', 'en:fish-meat-eggs'],\n",
       " , ordered=False),\n",
       " 'food_groups_en': CategoricalDtype(categories=['Alcoholic beverages', 'Beverages,Fruit juices',\n",
       "                   'Beverages,Plant-based milk substitutes',\n",
       "                   'Beverages,Sweetened beverages',\n",
       "                   'Beverages,Teas and herbal teas and coffees',\n",
       "                   'Beverages,Unsweetened beverages', 'Cereals and potatoes',\n",
       "                   'Cereals and potatoes,Bread',\n",
       "                   'Cereals and potatoes,Breakfast cereals',\n",
       "                   'Cereals and potatoes,Cereals',\n",
       "                   'Cereals and potatoes,Legumes',\n",
       "                   'Composite foods,One-dish meals',\n",
       "                   'Composite foods,Pizza pies and quiches',\n",
       "                   'Composite foods,Sandwiches',\n",
       "                   'Fats and sauces,Dressings and sauces',\n",
       "                   'Fats and sauces,Fats', 'Fish‚ Meat‚ Eggs,Eggs',\n",
       "                   'Fish‚ Meat‚ Eggs,Fish and seafood',\n",
       "                   'Fish‚ Meat‚ Eggs,Fish and seafood,Fatty fish',\n",
       "                   'Fish‚ Meat‚ Eggs,Fish and seafood,Lean fish',\n",
       "                   'Fish‚ Meat‚ Eggs,Meat,Meat other than poultry',\n",
       "                   'Fish‚ Meat‚ Eggs,Meat,Poultry',\n",
       "                   'Fish‚ Meat‚ Eggs,Processed meat', 'Fruits and vegetables',\n",
       "                   'Fruits and vegetables,Dried fruits',\n",
       "                   'Fruits and vegetables,Fruits',\n",
       "                   'Fruits and vegetables,Soups',\n",
       "                   'Fruits and vegetables,Vegetables',\n",
       "                   'Milk and dairy products,Cheese',\n",
       "                   'Milk and dairy products,Dairy desserts',\n",
       "                   'Milk and dairy products,Ice cream',\n",
       "                   'Milk and dairy products,Milk and yogurt',\n",
       "                   'Salty snacks,Appetizers', 'Salty snacks,Nuts',\n",
       "                   'Salty snacks,Salty and fatty products',\n",
       "                   'Sugary snacks,Biscuits and cakes',\n",
       "                   'Sugary snacks,Chocolate products', 'Sugary snacks,Pastries',\n",
       "                   'Sugary snacks,Sweets', 'Unknown',\n",
       "                   'Beverages,Artificially sweetened beverages',\n",
       "                   'Beverages,Waters and flavored waters',\n",
       "                   'Cereals and potatoes,Potatoes', 'Fish‚ Meat‚ Eggs,Offals',\n",
       "                   'Beverages,Fruit nectars', 'Fish‚ Meat‚ Eggs'],\n",
       " , ordered=False),\n",
       " 'states_en': string[python],\n",
       " 'brand_owner': string[python],\n",
       " 'ecoscore_score': dtype('float64'),\n",
       " 'ecoscore_grade': CategoricalDtype(categories=['a', 'b', 'c', 'd', 'e'], ordered=True),\n",
       " 'nutrient_levels_tags': string[python],\n",
       " 'product_quantity': dtype('float64'),\n",
       " 'data_quality_errors_tags': string[python],\n",
       " 'unique_scans_n': Int64Dtype(),\n",
       " 'popularity_tags': string[python],\n",
       " 'completeness': dtype('float64'),\n",
       " 'last_image_datetime': datetime64[ns, UTC],\n",
       " 'main_category_en': string[python],\n",
       " 'image_small_url': string[python],\n",
       " 'energy-kj_100g': dtype('float64'),\n",
       " 'energy-kcal_100g': dtype('float64'),\n",
       " 'energy_100g': dtype('float64'),\n",
       " 'fat_100g': dtype('float64'),\n",
       " 'saturated-fat_100g': dtype('float64'),\n",
       " 'monounsaturated-fat_100g': dtype('float64'),\n",
       " 'polyunsaturated-fat_100g': dtype('float64'),\n",
       " 'trans-fat_100g': dtype('float64'),\n",
       " 'cholesterol_100g': dtype('float64'),\n",
       " 'carbohydrates_100g': dtype('float64'),\n",
       " 'sugars_100g': dtype('float64'),\n",
       " 'fiber_100g': dtype('float64'),\n",
       " 'proteins_100g': dtype('float64'),\n",
       " 'salt_100g': dtype('float64'),\n",
       " 'sodium_100g': dtype('float64'),\n",
       " 'alcohol_100g': dtype('float64'),\n",
       " 'vitamin-a_100g': dtype('float64'),\n",
       " 'vitamin-d_100g': dtype('float64'),\n",
       " 'vitamin-c_100g': dtype('float64'),\n",
       " 'vitamin-b1_100g': dtype('float64'),\n",
       " 'vitamin-b2_100g': dtype('float64'),\n",
       " 'potassium_100g': dtype('float64'),\n",
       " 'calcium_100g': dtype('float64'),\n",
       " 'iron_100g': dtype('float64'),\n",
       " 'fruits-vegetables-nuts-estimate-from-ingredients_100g': dtype('float64'),\n",
       " 'nutrition-score-fr_100g': dtype('float64')}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dtype(df: pd.DataFrame, f_out: str) -> None:\n",
    "    \"\"\"Dump the dtype of a DataFrame to a text file, usable for read_csv.\n",
    "\n",
    "    The dtypes cannot be used as is, because we use pandas new types for strings,\n",
    "    categories etc. *unless* we import all the necessary dtypes at the beginning, but\n",
    "    that would be confusing for users. The only exception we make is for the ordered\n",
    "    categories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df :\n",
    "        DataFrame\n",
    "    f_out :\n",
    "        Path to the text file to which the dtype will be written.\n",
    "    \"\"\"\n",
    "    # init with the current dtypes, then overwrite those that do not support the\n",
    "    # roundtrip well\n",
    "    dump_dtype = df.dtypes.to_dict()\n",
    "    # unordered category\n",
    "    cols_ucats = [\n",
    "        (col_name, \"category\")\n",
    "        for col_name in df.select_dtypes(include=\"category\").columns.values\n",
    "        if not df[col_name].cat.ordered\n",
    "    ]\n",
    "    # print(\"category columns: \", cols_ucats)\n",
    "    dump_dtype.update(cols_ucats)\n",
    "    # string\n",
    "    # NB: select_dtypes() does (as of 2024-07) accept \"string\"\n",
    "    cols_string = [\n",
    "        (col_name, \"string\")\n",
    "        for col_name in df.select_dtypes(include=[\"string\"]).columns.values\n",
    "    ]\n",
    "    # print(\"string columns: \", cols_string)  # DEBUG\n",
    "    dump_dtype.update(cols_string)\n",
    "    # datetime\n",
    "    # dumped and read as objects, re-parsed to datetimes each time\n",
    "    cols_datetime = [\n",
    "        (col_name, \"object\")\n",
    "        for col_name in df.select_dtypes(include=\"datetimetz\").columns.values\n",
    "    ]\n",
    "    # print(\"datetimetz columns: \", cols_datetime)\n",
    "    dump_dtype.update(cols_datetime)\n",
    "    # numeric types\n",
    "    # TODO is it necessary ?\n",
    "    for col_dtype in (\"float\", \"UInt8\", \"Int8\", \"Int64\"):\n",
    "        dump_dtype.update(\n",
    "            [\n",
    "                (col_name, col_dtype)\n",
    "                for col_name in df.select_dtypes(include=col_dtype).columns.values\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # FIXME the dump contains line breaks that seem to confuse python on Google colab !?\n",
    "    with open(f_out, \"w\") as f:\n",
    "        print(dump_dtype, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE_FILE = \"../data/processed/dtype.txt\"\n",
    "dump_dtype(df=df, f_out=DTYPE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the filtered dataset\n",
    "FILTERED_OFF = \"../data/processed/off_products_subset.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(FILTERED_OFF, sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open new files to check consistency with the original\n",
    "with open(DTYPE_FILE) as f:\n",
    "    new_dtype = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(FILTERED_OFF, sep=\"\\t\", dtype=new_dtype, quoting=csv.QUOTE_NONE)\n",
    "# convert columns with datetimes\n",
    "for col_name in (\"created_datetime\", \"last_modified_datetime\", \"last_updated_datetime\", \"last_image_datetime\"):\n",
    "    if col_name in new_df:\n",
    "        # ISO 8601 dates\n",
    "        new_df[col_name] = pd.to_datetime(new_df[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>url</th>\n",
       "      <th>creator</th>\n",
       "      <th>created_datetime</th>\n",
       "      <th>last_modified_datetime</th>\n",
       "      <th>last_modified_by</th>\n",
       "      <th>last_updated_datetime</th>\n",
       "      <th>product_name</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>...</th>\n",
       "      <th>vitamin-a_100g</th>\n",
       "      <th>vitamin-d_100g</th>\n",
       "      <th>vitamin-c_100g</th>\n",
       "      <th>vitamin-b1_100g</th>\n",
       "      <th>vitamin-b2_100g</th>\n",
       "      <th>potassium_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>fruits-vegetables-nuts-estimate-from-ingredients_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000101209159</td>\n",
       "      <td>http://world-en.openfoodfacts.org/product/0000...</td>\n",
       "      <td>kiliweb</td>\n",
       "      <td>2018-02-22 10:56:57+00:00</td>\n",
       "      <td>2023-04-28 23:59:01+00:00</td>\n",
       "      <td>roboto-app</td>\n",
       "      <td>2024-02-09 14:48:49+00:00</td>\n",
       "      <td>Véritable pâte à tartiner noisettes chocolat noir</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>350 g</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000131327786</td>\n",
       "      <td>http://world-en.openfoodfacts.org/product/0000...</td>\n",
       "      <td>blakejones99</td>\n",
       "      <td>2024-06-01 20:48:44+00:00</td>\n",
       "      <td>2024-06-01 22:13:50+00:00</td>\n",
       "      <td>roboto-app</td>\n",
       "      <td>2024-06-01 22:13:50+00:00</td>\n",
       "      <td>Lime Cordial</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1l</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            code                                                url  \\\n",
       "0  0000101209159  http://world-en.openfoodfacts.org/product/0000...   \n",
       "1  0000131327786  http://world-en.openfoodfacts.org/product/0000...   \n",
       "\n",
       "        creator          created_datetime    last_modified_datetime  \\\n",
       "0       kiliweb 2018-02-22 10:56:57+00:00 2023-04-28 23:59:01+00:00   \n",
       "1  blakejones99 2024-06-01 20:48:44+00:00 2024-06-01 22:13:50+00:00   \n",
       "\n",
       "  last_modified_by     last_updated_datetime  \\\n",
       "0       roboto-app 2024-02-09 14:48:49+00:00   \n",
       "1       roboto-app 2024-06-01 22:13:50+00:00   \n",
       "\n",
       "                                        product_name generic_name quantity  \\\n",
       "0  Véritable pâte à tartiner noisettes chocolat noir         <NA>    350 g   \n",
       "1                                       Lime Cordial         <NA>       1l   \n",
       "\n",
       "   ... vitamin-a_100g vitamin-d_100g vitamin-c_100g vitamin-b1_100g  \\\n",
       "0  ...            NaN            NaN            NaN             NaN   \n",
       "1  ...            NaN            NaN            NaN             NaN   \n",
       "\n",
       "  vitamin-b2_100g potassium_100g calcium_100g iron_100g  \\\n",
       "0             NaN            NaN          NaN       NaN   \n",
       "1             NaN            NaN          NaN       NaN   \n",
       "\n",
       "  fruits-vegetables-nuts-estimate-from-ingredients_100g  \\\n",
       "0                                                NaN      \n",
       "1                                               30.0      \n",
       "\n",
       "  nutrition-score-fr_100g  \n",
       "0                    23.0  \n",
       "1                     NaN  \n",
       "\n",
       "[2 rows x 81 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67c217cb44a4c7e1aee5e5dab73f2dc17457b90fcf219f4075fac62127fe9571"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('scpo-bootcamp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
